#include <opencv2/opencv.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <iostream>
#include <chrono>

int main()
{
    std::cout << "=================================\n";
    std::cout << "ASL Hand Gesture Recognition System\n";
    std::cout << "Phase 0: Camera Capture Test\n";
    std::cout << "=================================\n\n";

    // Display OpenCV version
    std::cout << "âœ“ OpenCV Version: " << CV_VERSION << std::endl;

    auto start_time = std::chrono::high_resolution_clock::now();

    try
    {
        // Test camera access
        std::cout << "\nðŸ“· Testing camera access..." << std::endl;
        cv::VideoCapture cap(0);

        if (!cap.isOpened())
        {
            std::cout << "âš ï¸  No camera detected (expected in server environment)" << std::endl;
            std::cout << "âœ“ Camera code structure: Ready for hardware" << std::endl;
        }
        else
        {
            std::cout << "âœ“ Camera detected and accessible!" << std::endl;

            // Get camera properties
            int frame_width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
            int frame_height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);
            double fps = cap.get(cv::CAP_PROP_FPS);

            std::cout << "  - Resolution: " << frame_width << "x" << frame_height << std::endl;
            std::cout << "  - FPS: " << fps << std::endl;

            // Test frame capture
            cv::Mat frame;
            if (cap.read(frame))
            {
                std::cout << "âœ“ Frame capture: Working" << std::endl;
                std::cout << "  - Frame size: " << frame.cols << "x" << frame.rows << std::endl;
                std::cout << "  - Channels: " << frame.channels() << std::endl;

                // Save a test frame
                cv::imwrite("test_frame.jpg", frame);
                std::cout << "âœ“ Frame saved as test_frame.jpg" << std::endl;
            }

            cap.release();
        }

        // Test basic image processing operations that we'll need
        std::cout << "\nðŸ”„ Testing image processing pipeline..." << std::endl;

        // Create a synthetic hand-like shape for testing
        cv::Mat test_frame = cv::Mat::zeros(480, 640, CV_8UC3);

        // Draw a hand-like shape
        std::vector<cv::Point> hand_contour = {
            cv::Point(300, 400), cv::Point(320, 380), cv::Point(340, 360),
            cv::Point(360, 340), cv::Point(380, 320), cv::Point(400, 300),
            cv::Point(420, 280), cv::Point(440, 260), cv::Point(460, 240),
            cv::Point(480, 220), cv::Point(500, 200), cv::Point(520, 180),
            cv::Point(540, 160), cv::Point(560, 140), cv::Point(580, 120),
            cv::Point(580, 140), cv::Point(560, 160), cv::Point(540, 180),
            cv::Point(520, 200), cv::Point(500, 220), cv::Point(480, 240),
            cv::Point(460, 260), cv::Point(440, 280), cv::Point(420, 300),
            cv::Point(400, 320), cv::Point(380, 340), cv::Point(360, 360),
            cv::Point(340, 380), cv::Point(320, 400)};

        cv::fillPoly(test_frame, hand_contour, cv::Scalar(200, 180, 160));
        cv::putText(test_frame, "Synthetic Hand Shape", cv::Point(250, 450),
                    cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255), 2);

        // Test color space conversion (needed for MediaPipe)
        cv::Mat rgb_frame;
        cv::cvtColor(test_frame, rgb_frame, cv::COLOR_BGR2RGB);
        std::cout << "âœ“ BGR to RGB conversion: Working" << std::endl;

        // Test grayscale conversion
        cv::Mat gray_frame;
        cv::cvtColor(test_frame, gray_frame, cv::COLOR_BGR2GRAY);
        std::cout << "âœ“ Grayscale conversion: Working" << std::endl;

        // Test contour detection (for hand shape analysis)
        std::vector<std::vector<cv::Point>> contours;
        cv::findContours(gray_frame, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);
        std::cout << "âœ“ Contour detection: Working (" << contours.size() << " contours found)" << std::endl;

        // Performance test
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);

        std::cout << "\nâ±ï¸  Processing time: " << duration.count() << " microseconds" << std::endl;
        std::cout << "ðŸ“Š Performance: " << (1000000.0 / duration.count()) << " FPS potential" << std::endl;

        // Save test image
        cv::imwrite("synthetic_hand_test.jpg", test_frame);
        std::cout << "âœ“ Test image saved as synthetic_hand_test.jpg" << std::endl;

        std::cout << "\nðŸŽ¯ Camera and Image Processing: READY!" << std::endl;
        std::cout << "\nðŸ“‹ Next Phase: MediaPipe Integration" << std::endl;
        std::cout << "   - Hand landmark detection (21 points)" << std::endl;
        std::cout << "   - Real-time processing pipeline" << std::endl;
        std::cout << "   - Feature extraction for ML model" << std::endl;

        return 0;
    }
    catch (const cv::Exception &e)
    {
        std::cerr << "âŒ OpenCV Error: " << e.what() << std::endl;
        return -1;
    }
}